# MLOps Project: A Comprehensive Guide and Workflow

Welcome to this MLOps project, designed to demonstrate a robust pipeline for managing vehicle insurance data. This repository offers a hands-on demonstration of an industry-standard MLOps pipeline, showcasing the entire lifecycle of a Machine Learning projectâ€”from data ingestion and validation to deployment and CI/CD integration. 
---

## âœ¨ **Features**

### ğŸ”§ **End-to-End Pipeline**
- Automates the entire machine learning workflow.
- Modular components for flexibility and reusability.

### ğŸ› ï¸ **Robust Tooling**
- MongoDB Atlas for efficient database management.
- Python-based feature engineering and data transformation.
- Seamless integration with AWS services for cloud storage and deployment.

### ğŸŒ **Cloud-Ready Design**
- Integrated with AWS S3 for artifact management.
- Deployed on EC2 instances with Docker for scalability.

### ğŸ”„ **CI/CD Pipeline**
- Automated workflows using GitHub Actions.
- Self-hosted runners for continuous integration and deployment.

### ğŸŒ **Interactive Application**
- Web interface for real-time data insights and model predictions.

---

## ğŸ“š **Project Structure**

```plaintext
â”œâ”€â”€ notebook
â”‚   â”œâ”€â”€ mongoDB_demo.ipynb        # MongoDB integration demo
â”‚   â”œâ”€â”€ eda_feature_engineering.ipynb  # Exploratory Data Analysis & Feature Engineering
â”œâ”€â”€ src
â”‚   â”œâ”€â”€ configuration
â”‚   â”‚   â”œâ”€â”€ mongo_db_connections.py  # MongoDB connection utilities
â”‚   â”‚   â”œâ”€â”€ aws_connection.py        # AWS configuration scripts
â”‚   â”œâ”€â”€ entity
â”‚   â”‚   â”œâ”€â”€ config_entity.py         # Configuration entities
â”‚   â”‚   â”œâ”€â”€ artifact_entity.py       # Artifact structure definitions
â”‚   â”‚   â”œâ”€â”€ estimator.py             # Model training and evaluation utilities
â”‚   â”œâ”€â”€ data_access
â”‚   â”‚   â”œâ”€â”€ proj1_data.py            # Data fetching & transformations
â”‚   â”œâ”€â”€ components
â”‚   â”‚   â”œâ”€â”€ data_ingestion.py        # Data ingestion scripts
â”‚   â”‚   â”œâ”€â”€ data_validation.py       # Data validation scripts
â”‚   â”‚   â”œâ”€â”€ data_transformation.py   # Data transformation scripts
â”‚   â”‚   â”œâ”€â”€ model_trainer.py         # Model training scripts
â”‚   â”œâ”€â”€ aws_storage
â”‚   â”‚   â”œâ”€â”€ s3_estimator.py          # AWS S3 interaction utilities
â”œâ”€â”€ app.py                          # Main application entry point
â”œâ”€â”€ requirements.txt                # Dependency list
â”œâ”€â”€ setup.py                        # Local package setup
â”œâ”€â”€ pyproject.toml                  # Build system configuration
â”œâ”€â”€ Dockerfile                      # Docker configuration
â”œâ”€â”€ .dockerignore                   # Ignored files during Docker build
â”œâ”€â”€ .github
â”‚   â”œâ”€â”€ workflows
â”‚   â”‚   â”œâ”€â”€ aws.yaml                # CI/CD pipeline configuration
```

---

## âš™ï¸ **Installation and Setup**

### **Step 1: Create and Activate a Virtual Environment**

```bash
conda create -n vehicle python=3.10 -y
conda activate vehicle
```

### **Step 2: Install Dependencies**

Ensure all required packages are listed in `requirements.txt`, then run:

```bash
pip install -r requirements.txt
```

### **Step 3: Verify Installation**

```bash
pip list
```

---

## ğŸ—„ï¸ **MongoDB Setup**

### **Step 1: Cluster Creation**
- Sign up at [MongoDB Atlas](https://www.mongodb.com/atlas).
- Create a new cluster with default settings.

### **Step 2: Access Configuration**
- Add IP Address `0.0.0.0/0` to allow universal access.
- Set up a database user with credentials.

### **Step 3: Connection String**
- Navigate to *Database > Connect > Drivers*.
- Copy and modify the connection string to include your credentials.

### **Step 4: Data Upload**
- Use `mongoDB_demo.ipynb` to upload datasets to MongoDB.

### **Step 5: Verify Data**
- Browse uploaded data via MongoDB Atlas.

---

## ğŸ“ˆ **Data Pipeline Workflow**

### **1. Data Ingestion**
- Fetch and structure data from MongoDB.
- **Key Scripts**:
  - `data_access/proj1_data.py`
  - `components/data_ingestion.py`

### **2. Data Validation**
- Validate data against a schema (`config.schema.yaml`).
- **Key Scripts**:
  - `components/data_validation.py`

### **3. Data Transformation**
- Preprocess and transform data for model training.
- **Key Scripts**:
  - `components/data_transformation.py`

### **4. Model Training**
- Train machine learning models and save artifacts to AWS S3.
- **Key Scripts**:
  - `components/model_trainer.py`

---

## ğŸŒ **AWS Integration**

### **1. IAM Setup**
- Create an IAM user with `AdministratorAccess` policy.

### **2. S3 Bucket**
- Configure an S3 bucket named `my-model-mlopsproj`.

### **3. EC2 Instance**
- Deploy the app on an Ubuntu EC2 instance.
- Install Docker and required tools.

### **4. Environment Variables**
- Set AWS credentials in `constants/__init__.py`.

---

## ğŸ”„ **CI/CD Integration**

### **Step 1: GitHub Actions**
- Configure workflows in `.github/workflows/aws.yaml`.
- Add secrets for AWS credentials and repository configurations.

### **Step 2: Self-Hosted Runner**
- Set up a GitHub self-hosted runner on EC2 for automated deployments.

---

## ğŸ“‹ **Usage Instructions**

### **Run the Application**

```bash
python app.py
```

### **Access the Application**
- Visit `http://<EC2_PUBLIC_IP>:5080`.
- Trigger training via `/training` route.

---

## ğŸŒŸ **Highlights**

### **Complete MLOps Workflow**
- End-to-end pipeline from raw data ingestion to cloud deployment.

### **Cloud-Native Architecture**
- Leverages AWS for storage, deployment, and scalability.

### **Continuous Integration**
- Streamlined updates with GitHub Actions and Docker.

### **User-Friendly Interface**
- Simplifies operations for both technical and non-technical users.

---

## ğŸ™Œ **Acknowledgments**

Special thanks to:

- **MongoDB Atlas** for database solutions.
- **AWS** for cloud infrastructure support.
- **Python Community** for essential libraries and tools.

---

## ğŸ”— **Get in Touch**

We welcome contributions, suggestions, and feedback! Please feel free to open an issue or submit a pull request on this repository.

---

Thank you for exploring this project! We hope it inspires you to build scalable and efficient MLOps solutions. ğŸš€


